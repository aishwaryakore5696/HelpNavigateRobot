{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CareerCon 2019 - Help Navigate Robots\n",
    "Name-Aishwarya Kore\n",
    "Net Id-adk497"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The data has to be loaded in dataframes and filtered out to eliminate null and infinite values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data dimensions: (487680, 13) (3810, 3)\n",
      "Data after filtering: (487680, 13) (3810, 3)\n"
     ]
    }
   ],
   "source": [
    "# importing necessary libraries \n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "  \n",
    "# loading the dataset \n",
    "#please enter the correct loaction and file name of the input dataset\n",
    "df=pd.read_csv(\"C:/Users/admin/Desktop/aishu/study/sem2/ai/project1/data/X_train.csv\")\n",
    "#please enter the correct loaction and file name of the output dataset\n",
    "df2=pd.read_csv(\"C:/Users/admin/Desktop/aishu/study/sem2/ai/project1/data/y_train.csv\")\n",
    "print(\"Raw data dimensions:\",df.shape,df2.shape)\n",
    "\n",
    "#replace poditive and negative infinite values with nan and then drop all nan values present in the data\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df2=df2.replace([np.inf, -np.inf], np.nan)\n",
    "df=df.dropna(how='any',axis=0)\n",
    "df2=df2.dropna(how='any',axis=0)\n",
    "\n",
    "print(\"Data after filtering:\",df.shape,df2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE CORRELATION VISUALISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x109c3330>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "f,ax = plt.subplots(figsize=(8, 8))\n",
    "sns.heatmap(df.iloc[:,:].corr(), annot=True, linewidths=.5, fmt= '.1f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Note that the orientation X,Y,Z,W are highly correlated with each other and affect the predictions the most"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Group all the entries with same series id as we have one output class per series id\n",
    "##### Use various aggregate function for generating new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data X with new features: (3810, 40)\n"
     ]
    }
   ],
   "source": [
    "def modify(df):\n",
    "    dfnew=df[[\"series_id\",\"measurement_number\",\"orientation_X\",\"orientation_Y\",\"orientation_Z\",\"orientation_W\",\"angular_velocity_X\",\"angular_velocity_Y\",\"angular_velocity_Z\",\"linear_acceleration_X\",\"linear_acceleration_Y\",\"linear_acceleration_Z\"]]\n",
    "    temp1= dfnew.groupby(\"series_id\").mean()\n",
    "    temp2= dfnew.groupby(\"series_id\").median()\n",
    "    temp3= dfnew.groupby(\"series_id\").quantile()\n",
    "    temp4=dfnew.groupby(\"series_id\").std()\n",
    "    \n",
    "    df_train_mean=temp1[[\"orientation_X\",\"orientation_Y\",\"orientation_Z\",\"orientation_W\",\"angular_velocity_X\",\"angular_velocity_Y\",\"angular_velocity_Z\",\"linear_acceleration_X\",\"linear_acceleration_Y\",\"linear_acceleration_Z\"]]\n",
    "    df_train_median=temp2[[\"orientation_X\",\"orientation_Y\",\"orientation_Z\",\"orientation_W\",\"angular_velocity_X\",\"angular_velocity_Y\",\"angular_velocity_Z\",\"linear_acceleration_X\",\"linear_acceleration_Y\",\"linear_acceleration_Z\"]]\n",
    "    df_train_quantile=temp3[[\"orientation_X\",\"orientation_Y\",\"orientation_Z\",\"orientation_W\",\"angular_velocity_X\",\"angular_velocity_Y\",\"angular_velocity_Z\",\"linear_acceleration_X\",\"linear_acceleration_Y\",\"linear_acceleration_Z\"]]\n",
    "    df_train_std=temp4[[\"orientation_X\",\"orientation_Y\",\"orientation_Z\",\"orientation_W\",\"angular_velocity_X\",\"angular_velocity_Y\",\"angular_velocity_Z\",\"linear_acceleration_X\",\"linear_acceleration_Y\",\"linear_acceleration_Z\"]]\n",
    "    \n",
    "    df_train_mean.rename(columns={\"orientation_X\":\"orientation_X_mean\",\"orientation_Y\":\"orientation_Y_mean\",\"orientation_Z\":\"orientation_Z_mean\",\"orientation_W\":\"orientation_W_mean\",\"angular_velocity_X\":\"angular_velocity_X_mean\",\"angular_velocity_Y\":\"angular_velocity_Y_mean\",\"angular_velocity_Z\":\"angular_velocity_Z_mean\",\"linear_acceleration_X\":\"linear_acceleration_X_mean\",\"linear_acceleration_Y\":\"linear_acceleration_Y_mean\",\"linear_acceleration_Z\":\"linear_acceleration_Z_mean\"})\n",
    "    df_train_median.rename(columns={\"orientation_X\":\"orientation_X_median\",\"orientation_Y\":\"orientation_Y_median\",\"orientation_Z\":\"orientation_Z_median\",\"orientation_W\":\"orientation_W_median\",\"angular_velocity_X\":\"angular_velocity_X_median\",\"angular_velocity_Y\":\"angular_velocity_Y_median\",\"angular_velocity_Z\":\"angular_velocity_Z_median\",\"linear_acceleration_X\":\"linear_acceleration_X_median\",\"linear_acceleration_Y\":\"linear_acceleration_Y_median\",\"linear_acceleration_Z\":\"linear_acceleration_Z_median\"})\n",
    "    df_train_quantile.rename(columns={\"orientation_X\":\"orientation_X_q\",\"orientation_Y\":\"orientation_Y_q\",\"orientation_Z\":\"orientation_Z_q\",\"orientation_W\":\"orientation_W_q\",\"angular_velocity_X\":\"angular_velocity_X_q\",\"angular_velocity_Y\":\"angular_velocity_Y_q\",\"angular_velocity_Z\":\"angular_velocity_Z_q\",\"linear_acceleration_X\":\"linear_acceleration_X_q\",\"linear_acceleration_Y\":\"linear_acceleration_Y_q\",\"linear_acceleration_Z\":\"linear_acceleration_Z_q\"})\n",
    "    df_train_std.rename(columns={\"orientation_X\":\"orientation_X_std\",\"orientation_Y\":\"orientation_Y_std\",\"orientation_Z\":\"orientation_Z_std\",\"orientation_W\":\"orientation_W_std\",\"angular_velocity_X\":\"angular_velocity_X_std\",\"angular_velocity_Y\":\"angular_velocity_Y_std\",\"angular_velocity_Z\":\"angular_velocity_Z_std\",\"linear_acceleration_X\":\"linear_acceleration_X_std\",\"linear_acceleration_Y\":\"linear_acceleration_Y_std\",\"linear_acceleration_Z\":\"linear_acceleration_Z_std\"})\n",
    "    \n",
    "    X=pd.concat([df_train_mean,df_train_median,df_train_quantile,df_train_std], axis=1)\n",
    "    \n",
    "    return X\n",
    "\n",
    "X=modify(df)\n",
    "\n",
    "print(\"Shape of data X with new features:\",X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Here I noticed that adding standard deviation as a feature made a huge change in the accuracy from 60% to 90% that is because the s.d measurement represents each of 128 data rows most accurately as a group rather that calculating mean or median because we are considering the difference with each of these 128 values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we eliminiate the columns from the data that we do not need. Also the output values are in string we convert it to interger using a list of all the classes for better calculation putpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape of Y: (3810, 1)\n"
     ]
    }
   ],
   "source": [
    "#eliminate group_id and series_id colunms\n",
    "y_train=df2[[\"surface\"]].to_numpy()\n",
    "#convert string vals in surface to interger index using this list of all classes\n",
    "labels=['carpet','concrete','fine_concrete','hard_tiles','hard_tiles_large_space','soft_pvc','soft_tiles','tiled','wood']\n",
    "Y= np.zeros(len(y_train))\n",
    "for i in range(0,len(y_train)):\n",
    "    Y[i]=labels.index(y_train[i])\n",
    "Ydf=pd.DataFrame(Y)\n",
    "print(\"New shape of Y:\",Ydf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-fold Cross Validation\n",
    "#### We will evaluate metric(s) by cross-validation and also record fit/score times.\n",
    "#### here cv parameter is the no.of folds we have used cv=3 for best scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.98425197 -3.6488189  -3.58503937]\n",
      "[0.99801571 1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "lasso = linear_model.Lasso()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=16)\n",
    "cv_results = cross_validate(rf, X, Ydf, cv=3)\n",
    "sorted(cv_results.keys())\n",
    "scores = cross_validate(rf, X, Ydf, cv=3, scoring=('r2', 'neg_mean_squared_error'),return_train_score=True)\n",
    "print(scores['test_neg_mean_squared_error'])\n",
    "print(scores['train_r2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the training and testing data: (3790, 40) (20, 40) (3790, 1) (20, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# split X_train\n",
    "samples = 20\n",
    "start_x = X.shape[0] - samples\n",
    "X_train, X_test = X.iloc[:start_x], X.iloc[start_x:]\n",
    "\n",
    "# split y_train\n",
    "start_y = Ydf.shape[0] - samples\n",
    "y_train, y_test = Ydf.iloc[:start_y], Ydf.iloc[start_y:]\n",
    "\n",
    "print(\"Dimensions of the training and testing data:\",X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\utils\\validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression training accuracy= 0.4493403693931398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:939: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "lin_regression = LogisticRegression()\n",
    "lin_regression.fit(X_train,y_train)\n",
    "\n",
    "train_pred_lr = lin_regression.predict(X_train)\n",
    "\n",
    "print(\"Logistic Regression training accuracy=\",metrics.accuracy_score(y_train,train_pred_lr)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression tesing accuracy= 0.55\n"
     ]
    }
   ],
   "source": [
    "test_pred_lr=lin_regression.predict(X_test)\n",
    "print(\"Logistic Regression tesing accuracy=\",metrics.accuracy_score(y_test,test_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree training accuracy= 0.9939313984168865\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dmodel=DecisionTreeClassifier(splitter=\"random\",max_depth=15).fit(X_train,y_train)\n",
    "train_pred=dmodel.predict(X_train)\n",
    "print(\"Decision tree training accuracy=\",metrics.accuracy_score(y_train,train_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree testing accuracy= 0.7\n"
     ]
    }
   ],
   "source": [
    "ypred=dmodel.predict(X_test)\n",
    "print(\"Decision tree testing accuracy=\",metrics.accuracy_score(ypred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest training accuracy= 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=16)\n",
    "rf.fit(X_train,y_train);\n",
    "rf_pred=rf.predict(X_train)\n",
    "print(\"Random forest training accuracy=\",metrics.accuracy_score(rf_pred,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest testing accuracy= 0.9\n"
     ]
    }
   ],
   "source": [
    "rf_pred2=rf.predict(X_test)\n",
    "print(\"Random forest testing accuracy=\",metrics.accuracy_score(rf_pred2,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Multi Layer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP training accuracy= 0.8100263852242744\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "mlpy_pred=clf.predict(X_train)\n",
    "print(\"MLP training accuracy=\",metrics.accuracy_score(mlpy_pred,y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n",
      "MLP testing accuracy= 0.85\n"
     ]
    }
   ],
   "source": [
    "mlpy_pred2=clf.predict(X_test)\n",
    "print(mlpy_pred2.shape)\n",
    "print(\"MLP testing accuracy=\",metrics.accuracy_score(mlpy_pred2,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **From all the above models we get different accuracies so we choose the one with highest accuracy to predict the surface the robot is on and that would be the random forest classifier with an accuracy of 0.9 on testing data. \n",
    "#### **MLP also gives quite good accuracy on the data when its parameters are set right but it takes a lot of time to compute the predictions with that high value of parameters.\n",
    "#### **Also our final output should be converted to strings again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final predicted values of surfaces for test data:\n",
      "series_id                 surface\n",
      "     3790  hard_tiles_large_space\n",
      "     3791                concrete\n",
      "     3792                soft_pvc\n",
      "     3793                   tiled\n",
      "     3794  hard_tiles_large_space\n",
      "     3795                concrete\n",
      "     3796                    wood\n",
      "     3797           fine_concrete\n",
      "     3798                concrete\n",
      "     3799                   tiled\n",
      "     3800           fine_concrete\n",
      "     3801  hard_tiles_large_space\n",
      "     3802                   tiled\n",
      "     3803                    wood\n",
      "     3804                   tiled\n",
      "     3805                   tiled\n",
      "     3806                    wood\n",
      "     3807                   tiled\n",
      "     3808           fine_concrete\n",
      "     3809                soft_pvc\n"
     ]
    }
   ],
   "source": [
    "Y = pd.DataFrame(columns=['series_id','surface'])\n",
    "k=start_y\n",
    "for i in range(0,rf_pred2.shape[0]):\n",
    "    j=int(rf_pred2[i])\n",
    "    Y.loc[i] = k,labels[j]\n",
    "    k=k+1\n",
    "print(\"Final predicted values of surfaces for test data:\")\n",
    "print (Y.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write down the predictions to a file\n",
    "Y.to_csv(r'C:/Users/admin/Desktop/aishu/study/sem2/ai/project1/classification/output.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
